{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prices of new cars are fixed by manufacturer with additonal cost like sales tax, destination charges etc. so its very important for customers that the money they invest is worthy. After covid due to chip shortage new car production rate went drastically down. This caused increase in demand for used cars. Due to Russia-ukraine war, Supply chain got disrupted which made used car demand shoot up even higher.\n",
    "\n",
    "Due to rising inflation in united states, People have less money to spend and this has caused used car demand to go up even higher. For consumer its very important to get a good quality car for the money they spend and its very important for Car dealership to build their inventory with good cars which helps them in increasing their revenue and also increase customer satisfaction.\n",
    "\n",
    "In this project, i am trying to build various regression models which helps in predicting used car prices with high accuracy and provide some insights to car dealership on what features customers value more and drives the car prices high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import ydata_profiling\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.linear_model import (BayesianRidge, Lasso, LassoCV,\n",
    "                                  LinearRegression, Ridge, RidgeCV)\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error,\n",
    "                             mean_squared_log_error, r2_score)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, StratifiedKFold,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from tqdm import tqdm\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/vehicles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {cars.shape[0]} rows and {cars.shape[1]} columns in Dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Dataset profiling which gives insights into data.\n",
    "\n",
    "ydata_profiling.ProfileReport(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Used Pandas Profling report below are some of important things i noted\n",
    "\n",
    "* 4 Numeric columns and 14 Categorical columns\n",
    "* 15.8% of cells have Nan value\n",
    "* Price(target) and odometer is highly skewed\n",
    "* size has 71% of missing values followed by condition, cylinders, VIN, drive etc. These columns needs to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring all columns to understand data better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price column\n",
    "\n",
    "Price column is our target feature for which we need to build prediction for.\n",
    "* It has 15655 distinct values\n",
    "* It has maximum zeros. 32895 rows.\n",
    "* Mean is 75199, min is 0 and max is 3736928700. Values are highly skewed and need to be treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaving 880 rows with highest price point(Outliers)\n",
    "px.histogram(cars.nsmallest(n=426000, columns=['price']), x=\"price\", nbins=20, title=\"Price histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year column\n",
    "\n",
    "* Year has values ranging from 1900 to 2022. It has 1905 missing values.\n",
    "* Most of the cars are in 1990 to 2022 Year range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"year\", nbins=20, title=\"Number of cars categorized on Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manufacturer Column\n",
    "* There are 42 distinct Manufacturers \n",
    "* 17646 rows have values missing\n",
    "* Ford, Toyota and Chevy are top brands listed in this dataset.\n",
    "* 1995 to 2022 seems to cover most of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"manufacturer\", nbins=20, title=\"Number of cars categorized on Manufacturer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Column\n",
    "* Model has high cardinality with 29649 unique values.\n",
    "* ~5000 rows have values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_models = cars['model'].value_counts()[:50].index.tolist()\n",
    "px.histogram(cars.query('model in @top_50_models'), x=\"model\", nbins=20, title=\"Number of cars categorized on Model(Top 50 models)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### condition column\n",
    "* Condition has 6 unique values\n",
    "* 174104 rows have missing values\n",
    "* Good and excellent condition are in maximum number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"condition\", nbins=20,title=\"Number of cars categorized on Car condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cylinder column\n",
    "* Has 8 unique values\n",
    "* 177678 rows have missing values\n",
    "* 8, 6 and 4 constitue many values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"cylinders\", nbins=20, title=\"Number of cars categorized on Cylinders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuel column\n",
    "* Fuel has 5 unique values\n",
    "* 3013 rows have values missing\n",
    "* Gas, Other, Diesel constitute majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"fuel\", nbins=20, title=\"Number of cars categorized on Fuel type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odometer column\n",
    "* Odometers column is highly skewed\n",
    "* Only 4400 rows have missing values\n",
    "* Majority of odometers rating are below 350k miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"odometer\", nbins=500,title=\"Odometer histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title Status column\n",
    "* has 6 distinct values\n",
    "* Only 8242 rows have missing values\n",
    "* Most of vehicles have clean title status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"title_status\", title=\"Number of cars categorized on Title status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transmission column\n",
    "* Transmission has 3 unique values\n",
    "* 2556 rows have missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"transmission\", title=\"Number of cars categorized on Transmission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drive column\n",
    "* has 3 unique values\n",
    "* 130567 rows have missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"drive\", title=\"Number of cars categorized on Drive type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size Columns\n",
    "* has 4 unique values\n",
    "* 306361 rows have values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"size\", title=\"Number of cars categorized on Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type column\n",
    "* 13 unique values\n",
    "* 92858 rows have values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"type\", title=\"Number of cars categorized on Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paint color column\n",
    "* 12 distinct values\n",
    "* 130203 rows have values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(cars, x=\"paint_color\", title=\"Number of cars categorized on Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* Many categorical columns have Nan values. We need to either fill them in or remove the rows altogather.\n",
    "* Some of columns have outliers. This needs to be fixed.\n",
    "* Target column 'Price' has outliers and needs fixing. Price column is skewed as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars.reindex(columns=[\n",
    "    'id', 'region', 'year',\n",
    "    'manufacturer', 'model', 'condition',\n",
    "    'cylinders', 'fuel', 'odometer',\n",
    "    'title_status', 'transmission',\n",
    "    'VIN', 'drive', 'size',\n",
    "    'type', 'paint_color', 'state', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Below are number of Nan values in each column!\")\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dropping ID and VIN since it does not affect car prices!\")\n",
    "print(\"Dropping state and region as this does not affect \"\n",
    "      \"car prices much when there is demand!\")\n",
    "cars = cars.drop(columns=['id', 'VIN', 'state', 'region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(cars.isnull())\n",
    "fig.update_layout(\n",
    "    title = \"Heatmap showing Nan values in each column\")\n",
    "fig.update_layout(barmode='group', bargap=0.30,bargroupgap=0.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    'year',\n",
    "    'odometer'\n",
    "]\n",
    "cat_features = [\n",
    "    'manufacturer',\n",
    "    'model',\n",
    "    'condition',\n",
    "    'cylinders',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'transmission',\n",
    "    'drive',\n",
    "    'size',\n",
    "    'type',\n",
    "    'paint_color'\n",
    "]\n",
    "print(f\"These are numerical features in dataset: {num_features}\")\n",
    "print(f\"These are categorical features in dataset: {cat_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of cars dataset.\n",
    "cars_imputer = cars.copy()\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "def encode(data):\n",
    "    nonulls = np.array(data.dropna())\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return data\n",
    "\n",
    "# Encoding Categorical values in to Numerical using LabelEncoder()\n",
    "for i in tqdm(range(len(cat_features))):\n",
    "    encode(cars_imputer[cat_features[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the score on the entire dataset by filling missing values by 4 different iterative imputers\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    DecisionTreeRegressor(\n",
    "        max_features='sqrt',\n",
    "        random_state=0\n",
    "    ),\n",
    "    ExtraTreesRegressor(\n",
    "        n_estimators=10,\n",
    "        random_state=0\n",
    "    ),\n",
    "    KNeighborsRegressor(\n",
    "        n_neighbors=15\n",
    "    )\n",
    "]\n",
    "score = pd.DataFrame()\n",
    "for estimator in estimators:\n",
    "    print(f\"Estimating using {estimator.__class__.__name__} estimator!\")\n",
    "    imputer = IterativeImputer(estimator)\n",
    "    cars_impute = cars_imputer.copy()\n",
    "    for col in cars_imputer.columns:\n",
    "        impute_data=imputer.fit_transform(\n",
    "            cars_impute[col].values.reshape(-1,1)\n",
    "        )\n",
    "        impute_data=impute_data.astype('int64')\n",
    "        impute_data = pd.DataFrame(\n",
    "            np.ravel(impute_data)\n",
    "        )\n",
    "        cars_impute[col]=impute_data\n",
    "    X = cars_impute.iloc[:,:-1]\n",
    "    y = np.ravel(cars_impute.iloc[:,-1:])\n",
    "    score[estimator.__class__.__name__] = cross_val_score(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=6\n",
    "    )\n",
    "del cars_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE scores of each estimator for cv=6\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "means = -score.mean()\n",
    "errors = score.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title('MSE with Different Imputation Methods')\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels(means.index.tolist())\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above figure shows that Bayesian Ridge Imputer is best with lower MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values in Numerical features\n",
    "cars.isnull().sum()[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_num = cars[num_features]\n",
    "\n",
    "# Using estimators[0] = BayesianRidge to fill Nan values in Numerical features.\n",
    "imputer_num = IterativeImputer(estimators[0])\n",
    "impute_data = imputer_num.fit_transform(cars_num)\n",
    "cars[num_features] = impute_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values after filling\n",
    "cars.isnull().sum()[num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan values in Categorical features\n",
    "cars.isnull().sum()[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BayesianRidge imputer for categorical columns as well.\n",
    "cars_cat = cars[cat_features]\n",
    "encoder=preprocessing.LabelEncoder()\n",
    "\n",
    "for columns in cat_features:\n",
    "    encode(cars_cat[columns])\n",
    "    imputer = IterativeImputer(BayesianRidge())\n",
    "    impute_data = imputer.fit_transform(cars_cat[columns].values.reshape(-1, 1))\n",
    "    impute_data = impute_data.astype('int64')\n",
    "    impute_data = pd.DataFrame(impute_data)\n",
    "    impute_data = encoder.inverse_transform(impute_data.values.reshape(-1, 1))\n",
    "    cars_cat[columns]=impute_data\n",
    "cars[cat_features]=cars_cat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.isnull().sum()[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(cars.isnull())\n",
    "fig.update_layout(\n",
    "    title = \"Heatmap showing all Nan values are eliminated!\")\n",
    "fig.update_layout(barmode='group', bargap=0.30,bargroupgap=0.0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again check for Nan values on whole dataset! Just to make sure :)\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned data to disk just in case if i need fresh copy further down.\n",
    "cars.to_csv('cars_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_range(arr: list, col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Function to find outliers range for given Array and column\n",
    "    \"\"\"\n",
    "    x_values = sorted(arr[col].values.ravel())\n",
    "    q_25 = 25 / 100 * (len(x_values) + 1)\n",
    "    i_p = int(str(q_25).split(\".\")[0])\n",
    "    f_p = int(str(q_25).split(\".\")[1])\n",
    "    q1 = x_values[i_p] + f_p * (x_values[i_p + 1] - x_values[i_p])\n",
    "    q_75 = 75/100*(len(x_values)+1)\n",
    "    i_p = int(str(q_75).split(\".\")[0])\n",
    "    f_p = int(str(q_75).split(\".\")[1])\n",
    "    q3 = x_values[i_p] + f_p * (x_values[i_p + 1] - x_values[i_p])\n",
    "    iqr = q3 - q1\n",
    "    x_values_1 = q1 - 1.5 * iqr\n",
    "    x_values_2 = q3 + 1.5 * iqr\n",
    "    return (x_values_1, x_values_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_price(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Function to find min and max price to remove outliers\n",
    "    \"\"\"\n",
    "    range_ = []\n",
    "    q1, q3 = (df['logprice'].quantile([0.25,0.75]))\n",
    "    range_.append(q1 - 1.5 * (q3 - q1))\n",
    "    range_.append(q3 + 1.5 * (q3 - q1))\n",
    "    return (range_)\n",
    "\n",
    "# Adding logprice since price column is skewed. This brings normal distribution to price column.\n",
    "cars['logprice'] = np.log(cars['price'])\n",
    "x = cars['logprice']\n",
    "price_range = list(range(0, int(max(cars['logprice'])) + 1))\n",
    "red_square = dict(markerfacecolor='g', marker='s')\n",
    "plt.boxplot(x, vert=False)\n",
    "plt.xticks(price_range)\n",
    "plt.text(min_max_price(cars)[0]-0.3,1.05,str(round(min_max_price(cars)[0],2)))\n",
    "plt.text(min_max_price(cars)[1]-0.5,1.05,str(round(min_max_price(cars)[1],2)))\n",
    "plt.title(\"Box Plot of Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above Box plot shows that Prices below log 6.43 and above 12.44 are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title('Figure 2: Box Plot of Odometer')\n",
    "ax1.boxplot(cars['odometer'], vert=False, flierprops=red_square)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above box plot shows that Odometer rating anything below -107725.0 and above 282235.0 are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(12,5))\n",
    "\n",
    "#ploting boxplot\n",
    "o1, o2 = outliers_range(cars,'year')\n",
    "ax1.boxplot(sorted(cars['year']), vert=False, flierprops=red_square)\n",
    "ax1.set_xlabel(\"Years\")\n",
    "ax1.set_title(\"Figure 3: Box Plot of Year\")\n",
    "ax1.text(o1-8,1.05,str(round(o1,2)))\n",
    "\n",
    "#ploting histogram\n",
    "hist,bins=np.histogram(cars['year'])\n",
    "n, bins, patches = ax2.hist(x=cars['year'], bins=bins)\n",
    "ax2.set_xlabel(\"Years\")\n",
    "ax2.set_title(\"Figure 4: Histogram of Year\")\n",
    "for i in range(len(n)):\n",
    "    if(n[i]>2000):\n",
    "        ax2.text(bins[i],n[i]+3000,str(n[i]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above box plot shows that anything below 1995 and above 2022 are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers using outliers_range() funciton on logprice, odometer and year columns\n",
    "cars_new = cars.copy()\n",
    "out = np.array([\n",
    "    'logprice',\n",
    "    'odometer',\n",
    "    'year'\n",
    "])\n",
    "for col in out:\n",
    "    o1,o2 = outliers_range(cars_new, col)\n",
    "    cars_new = cars_new[(cars_new[col]>=o1) & (cars_new[col]<=o2)]\n",
    "    print('IQR of',col,'=',o1,o2)\n",
    "cars_new = cars_new[cars_new['price']!=0]\n",
    "cars_new.drop('logprice',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before process={cars.shape}\")\n",
    "print(f\"Shape After process={cars_new.shape}\")\n",
    "print(\n",
    "    f\"Total {cars.shape[0]-cars_new.shape[0]} rows \"\n",
    "    f\"and {cars.shape[1]-cars_new.shape[1]} columns were removed\")\n",
    "cars_new.to_csv(\"vehicles_finalized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a nutshell below Data cleanups were done\n",
    "\n",
    "* Dropped VIN and state columns. VIN doesn't add any value for price prediction and state is same info as region.\n",
    "* Used BayesianRidge, DecisionTreeRegressor, ExtraTreesRegressor, KNeighboursRegressor as estimator for Imputer method and found that BayesianRidge had lower MSE so used it to fill missing values for Categorical values.\n",
    "* Found outliers in Price, Odometer and Year columns and removed them using IQR.\n",
    "\n",
    "### Totally 62427 rows were eliminated while removing outliers from Year, Price and Odometer columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization After data prepration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned = cars_new.copy()\n",
    "cars_cleaned['year'] = cars_cleaned['year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_sample = cars_cleaned.sample(1000)\n",
    "cars_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a pairplot to view distribution of numerical features.\n",
    "colors = iter([\n",
    "    'xkcd:red purple', 'xkcd:pale teal', 'xkcd:warm purple',\n",
    "    'xkcd:light forest green', 'xkcd:blue with a hint of purple',\n",
    "    'xkcd:light peach', 'xkcd:dusky purple', 'xkcd:pale mauve',\n",
    "    'xkcd:bright sky blue'])\n",
    "\n",
    "def my_scatter(x,y, **kwargs):\n",
    "    kwargs['color'] = next(colors)\n",
    "    plt.scatter(x,y, **kwargs)\n",
    "\n",
    "def my_hist(x, **kwargs):\n",
    "    kwargs['color'] = next(colors)\n",
    "    plt.hist(x, **kwargs)\n",
    "\n",
    "g = sns.PairGrid(cars_sample)\n",
    "g.map_diag(my_hist)\n",
    "g.map_offdiag(my_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair plot is not very conclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(cars_cleaned, x=\"price\", nbins=20, title=\"Price histogram\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_generator(df=pd.DataFrame(), x='', y='', title='', hue=''):\n",
    "    \"\"\"\n",
    "    Function which take df, x, y, title and hue as input\n",
    "    and generates a bar plot using seaborn.barplot.\n",
    "    \"\"\"\n",
    "    fig, axis=plt.subplots()\n",
    "    if hue:\n",
    "        fig.set_size_inches(10, 6)\n",
    "        sns.barplot(x=x, y=y, data=df, ax=axis, hue=hue)\n",
    "    else:\n",
    "        fig.set_size_inches(10, 6)\n",
    "        sns.barplot(x=x, y=y, data=df, ax=axis)\n",
    "    axis.set_title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'fuel', 'price', 'Car price by Fuel Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid cars have lower price. Diesel cars cost more than electric ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'fuel', 'price', 'Car price by Fuel Type with condition as hue', hue='condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrespective of fuel type, Car condition decides the car prices. Salvaged cars have lower price point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'year', 'price', 'Car price by Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car prices are ever increasing starting 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'condition', 'price', 'Car price by Condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'condition', 'price', 'Car price by Condition', hue='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above 2 plots clearly shows that car condition drives the car price. Size of car impacts the prices as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'transmission', 'price', 'Car price by Transmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual car prices are low. Other types transmission have higher prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'transmission', 'price', 'Car price by Transmission, hue by size', hue='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'type', 'price', 'Car price by Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'manufacturer', 'price', 'Car price by manufacturer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'size', 'price', 'Car price by Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'size', 'price', 'Car price by Size and hue as drive', hue='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'drive', 'price', 'Car price by Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_generator(cars_cleaned, 'drive', 'price', 'Car price by Drive and hue as size', hue='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['year','odometer']\n",
    "cat_features = [\n",
    "    'manufacturer',\n",
    "    'model',\n",
    "    'condition',\n",
    "    'cylinders',\n",
    "    'fuel',\n",
    "    'title_status',\n",
    "    'transmission',\n",
    "    'drive',\n",
    "    'size',\n",
    "    'type',\n",
    "    'paint_color'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all categorical values to numerical values using sklearn's LabelEncoder.\n",
    "#### Converting price to logarithmic scale since data is skewed and its not normally distributed\n",
    "#### Normalizing other numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "cars_cleaned[cat_features] = cars_cleaned[cat_features].apply(\n",
    "    label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling numerical data\n",
    "norm = StandardScaler()\n",
    "cars_cleaned['price'] = np.log(cars_cleaned['price'])\n",
    "cars_cleaned['odometer'] = norm.fit_transform(np.array(cars_cleaned['odometer']).reshape(-1,1))\n",
    "cars_cleaned['year'] = norm.fit_transform(np.array(cars_cleaned['year']).reshape(-1,1))\n",
    "cars_cleaned['model'] = norm.fit_transform(np.array(cars_cleaned['model']).reshape(-1,1))\n",
    "\n",
    "# Scaling target variable\n",
    "q1, q3 = (cars_cleaned['price'].quantile([0.25,0.75]))\n",
    "o1 = q1-1.5*(q3-q1)\n",
    "o2 = q3+1.5*(q3-q1)\n",
    "cars_cleaned = cars_cleaned[(cars_cleaned.price>=o1) & (cars_cleaned.price<=o2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 90% of dataset as Training data and 10% as Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, n):\n",
    "    \"\"\"\n",
    "    Function to split training and test dataset\n",
    "    \"\"\"\n",
    "    X = df.iloc[:,n]\n",
    "    y = df.iloc[:,-1:].values.T\n",
    "    y = y[0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        train_size=0.9,\n",
    "        test_size=0.1,\n",
    "        random_state=0\n",
    "    )\n",
    "    return (X_train,X_test,y_train,y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(\n",
    "    cars_cleaned,\n",
    "    list(range(len(list(cars_cleaned.columns))-1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Function to remove negative values predicted by models.\n",
    "    \"\"\"\n",
    "    index_ = [index for index in range(len(y_pred)) if(y_pred[index]>0)]\n",
    "    y_pred = y_pred[index_]\n",
    "    y_test = y_test[index_]\n",
    "    y_pred[y_pred<0]\n",
    "    return (y_test,y_pred)\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Function to evalute the model\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    result.append(mean_squared_log_error(y_test, y_pred))\n",
    "    result.append(np.sqrt(result[0]))\n",
    "    result.append(r2_score(y_test,y_pred))\n",
    "    result.append(round(r2_score(y_test,y_pred)*100,4))\n",
    "    return (result)\n",
    "\n",
    "# Dataframe to store the performance of each model\n",
    "# Using MSLE since we have applied logarithmic to price target variable.\n",
    "accuracy = pd.DataFrame(index=['MSLE', 'Root MSLE', 'R2 Score','Accuracy(%)'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 14))}]\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm)  \n",
    "\n",
    "# Performing GridSearchCV with RFE\n",
    "model_cv = GridSearchCV(\n",
    "    estimator = rfe, \n",
    "    param_grid = hyper_params, \n",
    "    scoring= 'r2', \n",
    "    cv = folds, \n",
    "    verbose = 1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "model_cv.fit(X_train, y_train)   \n",
    "\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_traces(go.Line(x=cv_results[\"param_n_features_to_select\"], y=cv_results[\"mean_test_score\"], mode='lines', name=\"Test Score\"))\n",
    "fig.add_traces(go.Line(x=cv_results[\"param_n_features_to_select\"], y=cv_results[\"mean_train_score\"], mode='lines', name=\"Train Score\"))\n",
    "fig.update_layout(\n",
    "    title=\"Optimal number of features\",\n",
    "    xaxis_title=\"Number of features\",\n",
    "    yaxis_title=\"R2 Score\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on above graph picking 10 as optimal number of features\n",
    "n_features_optimal = 10\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error/accuracy\n",
    "y_test_1, y_pred_1 = remove_neg(\n",
    "    y_test,\n",
    "    y_pred\n",
    ")\n",
    "r1_lr = evaluate(y_test_1,y_pred_1)\n",
    "\n",
    "print(f\"MSLE : {r1_lr[0]}\")\n",
    "print(f\"Root MSLE : {r1_lr[1]}\")\n",
    "print(f\"R2 Score : {r1_lr[2]} or {r1_lr[3]}%\")\n",
    "\n",
    "accuracy['Linear Regression'] = r1_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_test, y=y_pred, labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Linear regression: Used Car Prediction with Log Price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=np.exp(y_test), y=np.exp(y_pred), labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Linear regression: Used Car Prediction with Actual Price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=X_train.columns, y=rfe.estimator.coef_, title=\"Linear Regression with RFE Model Coefs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are highlights from Linear Regression model with RFE\n",
    "\n",
    "* Model accuracy is ~63%\n",
    "* Year is most important feature. Higher the year higher the price. Same for Cylinders.\n",
    "* Odometer has higher negative coef. Higher the odometer higher the penalty.\n",
    "* Paint color does not affect car price much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting value of alpha\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,400)\n",
    "model = RidgeCV(alphas=alphas)\n",
    "visualizer = AlphaSelection(model)\n",
    "visualizer.fit(X_train,y_train)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using alpha found in above graph\n",
    "\n",
    "ridge_model = Ridge(alpha=23.357,solver='auto')\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_test, y=y_pred, labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Ridge: Used Car Prediction with Log Price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=np.exp(y_test), y=np.exp(y_pred), labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Ridge: Used Car Prediction with Actual price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error/accuracy\n",
    "\n",
    "y_test_2, y_pred_2 = remove_neg(\n",
    "    y_test,\n",
    "    y_pred\n",
    ")\n",
    "r2_ridge = evaluate(y_test_2, y_pred_2)\n",
    "\n",
    "print(f\"MSLE : {r2_ridge[0]}\")\n",
    "print(f\"Root MSLE : {r2_ridge[1]}\")\n",
    "print(f\"R2 Score : {r2_ridge[2]} or {r2_ridge[3]}%\")\n",
    "\n",
    "accuracy['Ridge Regression']=r2_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=X_train.columns, y=ridge_model.coef_, title=\"Ridge Model Coefs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are highlights from Ridge Regression model with best alpha=23.357\n",
    "\n",
    "* Model accuracy is ~63%\n",
    "* Ridge Model coefs are similar to Linear Regression model\n",
    "* Car Year drives price higher.\n",
    "* Odometer reading drives it lower.\n",
    "* Cylinders, Transmission, title status, fuel drives the price of used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting value of alpha\n",
    "\n",
    "alphas = 10**np.linspace(10,-2,400)\n",
    "model = LassoCV(alphas=alphas)\n",
    "visualizer = AlphaSelection(model)\n",
    "visualizer.fit(X_train,y_train)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model object and fitting it\n",
    "lasso_model = Lasso(alpha=0.010)\n",
    "lasso_model.fit(X_train,y_train)\n",
    "y_pred = lasso_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error/accuracy\n",
    "\n",
    "y_test_3, y_pred_3 = remove_neg(\n",
    "    y_test,\n",
    "    y_pred\n",
    ")\n",
    "r3_lasso = evaluate(y_test_3,y_pred_3)\n",
    "\n",
    "print(f\"MSLE : {r3_lasso[0]}\")\n",
    "print(f\"Root MSLE : {r3_lasso[1]}\")\n",
    "print(f\"R2 Score : {r3_lasso[2]} or {r3_lasso[3]}%\")\n",
    "\n",
    "accuracy['Lasso Regression'] = r3_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_test, y=y_pred, labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Lasso Model: Used Car Prediction with Log price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=np.exp(y_test), y=np.exp(y_pred), labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Lasso Model: Used Car Prediction with Actual price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=X_train.columns, y=lasso_model.coef_, title=\"Lasso Model Coefs\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are highlights from Lasso Regression model with best alpha=0.010\n",
    "\n",
    "* Model accuracy is ~63%\n",
    "* Lasso Model coefs are similar to Ridge / Linear Regression model\n",
    "* Car Year drives price higher.\n",
    "* Odometer reading drives it lower.\n",
    "* Cylinders, Transmission, title status, fuel drives the price of used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    random_state=0,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.5,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "random_forest_reg.fit(X_train,y_train)\n",
    "y_pred = random_forest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r5_rf = evaluate(y_test,y_pred)\n",
    "print(f\"MSLE : {r5_rf[0]}\")\n",
    "print(f\"Root MSLE : {r5_rf[1]}\")\n",
    "print(f\"R2 Score : {r5_rf[2]} or {r5_rf[3]}%\")\n",
    "accuracy['RandomForest Regressor']=r5_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=y_test, y=y_pred, labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Random Forest: Used Car Prediction with Log price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=np.exp(y_test), y=np.exp(y_pred), labels={'x': \"Actual Car Price\", 'y': \"Predicted Car Price\"}, title=\"Random Forest: Used Car Prediction with Actual price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = random_forest_reg.feature_importances_\n",
    "features = X_train.columns\n",
    "fig = px.bar(x=features, y=importances, title=\"Random Forest Regression Feature Importance\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are highlights from Random Forest Regression\n",
    "\n",
    "* Model accuracy is ~91%\n",
    "* Year is the most important feature, Size is least important feature.\n",
    "* Odometer, Model, Manufacturer, Cylinders Fuel are major factors affecting used car price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = accuracy.loc['Accuracy(%)']\n",
    "model_accuracy = pd.DataFrame({'Algorithm':model_accuracy.index, 'Accuracy':model_accuracy.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(model_accuracy, x='Algorithm', y='Accuracy', title='Model Performance!', markers=True)\n",
    "fig.update_traces(textposition=\"bottom right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Above plot we can see that Random Foreste Regression based model has higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this model for later use\n",
    "pickle.dump(random_forest_reg, open('random_forest_reg.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation to Car dealership\n",
    "\n",
    "* Year, Odometer are most important items which consumers value most and determines price range of the car.\n",
    "* Diesel and Electric can sell for higher prices when compared to gas car.\n",
    "* Higher No of cylinders drive the car price up.\n",
    "* Title status and condition affects the prices. Salvaged cars are penalized more and brings down prices.\n",
    "* rwd are penalized more when compared to fwd/4wd. Rwd cars have lower price points.\n",
    "* Automatic and other transmission type have higer price points and Manual reduces the car price.\n",
    "\n",
    "These are some of recommendation which car dealership can use to procure used car to drive sales up and provide great customer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here i have tried to deploy my model which car dealership can use to get a used cars price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"year\",\n",
    "    \"manufacturer\",\n",
    "    \"model\",\n",
    "    \"condition\",\n",
    "    \"cylinders\",\n",
    "    \"fuel\",\n",
    "    \"odometer\",\n",
    "    \"title_status\",\n",
    "    \"transmission\",\n",
    "    \"drive\",\n",
    "    \"size\",\n",
    "    \"type\",\n",
    "    \"paint_color\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading my best model from disk for prediction\n",
    "my_best_model = pickle.load(open('random_forest_reg.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vehicles_finalized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car dealership can use below python function to get predicted car prices by providing values for all below arguments\n",
    "\n",
    "1. **Year**: 1995 to 2022 </br></br>\n",
    "\n",
    "2. **Odometer**: Integer value greater than 0 </br></br>\n",
    "\n",
    "3. **Manufacturer**: Use one of below values. </br></br>\n",
    "    'infiniti' 'gmc' 'chevrolet' 'toyota' 'ford' 'jeep' 'nissan' 'ram' </br>\n",
    "    'mazda' 'cadillac' 'honda' 'dodge' 'lexus' 'jaguar' 'buick' 'chrysler' </br>\n",
    "    'volvo' 'audi' 'lincoln' 'alfa-romeo' 'subaru' 'acura' 'hyundai' </br>\n",
    "    'mercedes-benz' 'bmw' 'mitsubishi' 'volkswagen' 'porsche' 'kia' 'rover' </br>\n",
    "    'ferrari' 'mini' 'pontiac' 'fiat' 'tesla' 'saturn' 'mercury' </br>\n",
    "    'harley-davidson' 'aston-martin' 'land rover' 'morgan' </br></br>\n",
    " \n",
    "4. **Condition**: Use one of below values. </br></br>\n",
    "    'fair' 'good' 'excellent' 'like new' 'new' 'salvage'</br></br>\n",
    "    \n",
    "5. **Cylinders**: Use one of below values. </br></br>\n",
    "    '5 cylinders' '8 cylinders' '6 cylinders' '4 cylinders' '3 cylinders' '10 cylinders' 'other' '12 cylinders'</br></br>\n",
    "\n",
    "6. **Fuel**: Use one of below values. </br></br>\n",
    "    'gas' 'other' 'diesel' 'hybrid' 'electric'</br></br>\n",
    "\n",
    "7. **Transmission**: Use one of below values. </br></br>\n",
    "    'automatic' 'other' 'manual'</br></br>\n",
    "\n",
    "8. **Drive**: Use one of below values. </br></br>\n",
    "    '4wd' 'rwd' 'fwd' </br></br>\n",
    "   \n",
    "9. **Size**: Use one of below values. </br></br>\n",
    "    'full-size' 'mid-size' 'compact' 'sub-compact'  </br></br>\n",
    "\n",
    "10. **Type**: Use one of below values. </br></br>\n",
    "    'offroad' 'pickup' 'truck' 'other' 'coupe' 'SUV' 'hatchback' 'mini-van' 'sedan' 'bus' 'convertible' 'wagon' 'van'</br></br>\n",
    "    \n",
    "11. **Paint Color**: Use one of below values. </br></br>\n",
    "    'grey' 'white' 'blue' 'red' 'black' 'silver' 'brown' 'yellow' 'orange' 'green' 'custom' 'purple' </br></br>\n",
    "  \n",
    "12. **Model**: Use right model names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_used_cars_prices(\n",
    "        year=2019,\n",
    "        manufacturer='bmw',\n",
    "        model='g series',\n",
    "        condition='good',\n",
    "        cylinders='5 cylinders',\n",
    "        fuel='gas',\n",
    "        odometer=70000,\n",
    "        title_status='clean',\n",
    "        transmission='automatic',\n",
    "        drive='4wd',\n",
    "        size='full-size',\n",
    "        type_='coupe',\n",
    "        paint_color='red'):\n",
    "    \"\"\"\n",
    "    Function to predict Used car prices based on below parameters.\n",
    "    \"year\",\n",
    "    \"manufacturer\",\n",
    "    \"model\",\n",
    "    \"condition\",\n",
    "    \"cylinders\",\n",
    "    \"fuel\",\n",
    "    \"odometer\",\n",
    "    \"title_status\",\n",
    "    \"transmission\",\n",
    "    \"drive\",\n",
    "    \"size\",\n",
    "    \"type\",\n",
    "    \"paint_color\"\n",
    "    \"\"\"\n",
    "    # Get normalized value of odometer and year\n",
    "    year_odometer = pd.DataFrame(\n",
    "        data=[[year, odometer]],\n",
    "        columns=['year','odometer']\n",
    "    )\n",
    "    norm = StandardScaler()\n",
    "    norm.fit(df[['year', 'odometer']])\n",
    "    standardvalues=norm.transform(df[['year', 'odometer']])\n",
    "    df['year']=standardvalues[:,:1].flatten()\n",
    "    df['odometer']=standardvalues[:,1:].flatten()\n",
    "    values = norm.transform(year_odometer[['year', 'odometer']]).flatten()\n",
    "    input_ = pd.DataFrame(data=[[\n",
    "        values[0],\n",
    "        list(df['manufacturer'].unique()).index(manufacturer),\n",
    "        list(df['model'].unique()).index(model),\n",
    "        list(df['condition'].unique()).index(condition),\n",
    "        list(df['cylinders'].unique()).index(cylinders),\n",
    "        list(df['fuel'].unique()).index(fuel),\n",
    "        values[1],\n",
    "        list(df['title_status'].unique()).index(title_status),\n",
    "        list(df['transmission'].unique()).index(transmission),\n",
    "        list(df['drive'].unique()).index(drive),\n",
    "        list(df['size'].unique()).index(size),\n",
    "        list(df['type'].unique()).index(type_),\n",
    "        list(df['paint_color'].unique()).index(paint_color),]\n",
    "    ],columns=features)\n",
    "    pred = my_best_model.predict(input_)\n",
    "    price = np.exp(pred[0])\n",
    "    print(f\"Predictied price of {manufacturer} {model}->{year} car is: {price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_used_cars_prices(\n",
    "    year=2022,\n",
    "    manufacturer='infiniti',\n",
    "    model='g series',\n",
    "    condition='good',\n",
    "    cylinders='5 cylinders',\n",
    "    fuel='gas',\n",
    "    odometer=70000,\n",
    "    title_status='clean',\n",
    "    transmission='automatic',\n",
    "    drive='4wd',\n",
    "    size='full-size',\n",
    "    type_='coupe',\n",
    "    paint_color='red'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_used_cars_prices(\n",
    "    year=1995,\n",
    "    manufacturer='bmw',\n",
    "    model='525i',\n",
    "    condition='salvage',\n",
    "    cylinders='5 cylinders',\n",
    "    fuel='gas',\n",
    "    odometer=170000,\n",
    "    title_status='clean',\n",
    "    transmission='automatic',\n",
    "    drive='rwd',\n",
    "    size='full-size',\n",
    "    type_='coupe',\n",
    "    paint_color='black'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_used_cars_prices(\n",
    "    year=1995,\n",
    "    manufacturer='honda',\n",
    "    model='odyssey',\n",
    "    condition='salvage',\n",
    "    cylinders='5 cylinders',\n",
    "    fuel='gas',\n",
    "    odometer=270000,\n",
    "    title_status='clean',\n",
    "    transmission='automatic',\n",
    "    drive='4wd',\n",
    "    size='full-size',\n",
    "    type_='coupe',\n",
    "    paint_color='red'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_used_cars_prices(\n",
    "    year=2020,\n",
    "    manufacturer='tesla',\n",
    "    model='model 3 long range sedan',\n",
    "    condition='good',\n",
    "    cylinders='5 cylinders',\n",
    "    fuel='electric',\n",
    "    odometer=3996,\n",
    "    title_status='clean',\n",
    "    transmission='other',\n",
    "    drive='4wd',\n",
    "    size='full-size',\n",
    "    type_='sedan',\n",
    "    paint_color='white'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also build a basic Flask or Django web app which accepts these values from UI and runs this function to send predicted prices.\n",
    "\n",
    "# This enables a full e2e solution for Used Car Price prediction ML application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Continue to analyse each features further and remove features which does not affect prices much to improve model performance.\n",
    "* Try to deploy a basic Flask/Django application to build e2e ML solution.\n",
    "* Apply XGBoost and other algorightm once we go through it in future modules.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
